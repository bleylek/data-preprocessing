{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preprocessing**"
      ],
      "metadata": {
        "id": "OKw7Jb_lAloy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the Libraries"
      ],
      "metadata": {
        "id": "rs9IIuiyAqaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "5TNH7_PDAqMq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the Dataset"
      ],
      "metadata": {
        "id": "u-4E2ofdERNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('/content/Data.csv')\n",
        "X = dataset.iloc[:, :-1].values # : This selects all rows in the DataFrame. :-1 This selects all columns except the last one.\n",
        "y = dataset.iloc[:, -1].values # -1 means the last column"
      ],
      "metadata": {
        "id": "8fmFRaPJEVsz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FdPXUh4H2yF",
        "outputId": "ffa3689f-d475-40e8-e0d5-f3a910e7938c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ux5kDa3FH6jo",
        "outputId": "98a4f163-54cd-4f52-a98d-6e4af1a84e5a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taking Care of Missing Data"
      ],
      "metadata": {
        "id": "fdlibdhnPmMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the SimpleImputer class from sklearn.impute for handling missing data\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Create an instance of SimpleImputer to replace missing values (np.nan) with the mean of the column\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "\n",
        "# Fit the imputer on the 2nd and 3rd columns (index 1 and 2) of X to compute the mean for each column\n",
        "imputer.fit(X[:, 1:3])\n",
        "\n",
        "# Replace the missing values in the 2nd and 3rd columns of X with the computed mean values\n",
        "X[:, 1:3] = imputer.transform(X[:, 1:3])"
      ],
      "metadata": {
        "id": "gnyXdqiNH7yD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exDedJL_St0A",
        "outputId": "eb5546f7-f073-49f1-e91a-b93c0e9eec79"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 63777.77777777778]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' 38.77777777777778 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding Categorical Data"
      ],
      "metadata": {
        "id": "bsEhwoFDUuPw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding the Independent Variable"
      ],
      "metadata": {
        "id": "XnH7owZfY6Rs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer # Used to apply transformations (like encoding or scaling) to specific columns of a dataset while leaving the rest unchanged.\n",
        "from sklearn.preprocessing import OneHotEncoder # OneHotEncoder is used to convert categorical data into a one-hot encoded format (binary vectors)\n",
        "\n",
        "# Create a ColumnTransformer to apply OneHotEncoding to the first column (index 0) remainder='passthrough': Keeps all other columns as they are, without any transformation.\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
        "\n",
        "# Apply the transformation and convert the resulting structure to a NumPy array for easier handling.\n",
        "X = np.array(ct.fit_transform(X))"
      ],
      "metadata": {
        "id": "Jttnh0EEUwAm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUE_sJcGWqmz",
        "outputId": "fbf3a134-9d1e-45d3-8604-753baa72b475"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding the Dependent Variable"
      ],
      "metadata": {
        "id": "Foq53eSMY-oe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ],
      "metadata": {
        "id": "-WrqR_b5WreG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a01dVHAZqfn",
        "outputId": "f522880a-03c2-466b-e4bf-5c98bca83999"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the Dataset into the Training Set and the Test Set"
      ],
      "metadata": {
        "id": "5A_ZU5gbbgNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"
      ],
      "metadata": {
        "id": "oi95A_vnZrT4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crD9-YGXeDVh",
        "outputId": "afb93aa4-f7ea-4605-d713-4d862793711f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 35.0 58000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJ2kn25IeG2M",
        "outputId": "77018271-453c-4598-a0a0-df23cf3eb22c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 30.0 54000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWCg6SQxePtL",
        "outputId": "fe28adf6-f5c8-4703-b1f8-fa369b7cde33"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHJGAJlTeTqg",
        "outputId": "c0075583-3a15-4d69-d961-f0d48dc91fda"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Scaling"
      ],
      "metadata": {
        "id": "spA9dNuoboQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\n",
        "X_test[:, 3:] = sc.transform(X_test[:, 3:])"
      ],
      "metadata": {
        "id": "AmGsME5zoOSm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIzIak2Mrs3Z",
        "outputId": "4f0edb77-de9c-4cea-e2da-c7b4b570b963"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n",
            " [0.0 1.0 0.0 -0.014117293757057777 -0.07013167641635372]\n",
            " [1.0 0.0 0.0 0.566708506533324 0.633562432710455]\n",
            " [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n",
            " [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n",
            " [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]\n",
            " [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]\n",
            " [1.0 0.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDSe0u7BrwNm",
        "outputId": "edb8399c-db54-4d46-97de-16639d6d972f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 -1.4661817944830124 -0.9069571034860727]\n",
            " [1.0 0.0 0.0 -0.44973664397484414 0.2056403393225306]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Standartlaştırma ve fit_transform\n",
        "sc.fit_transform(X_train[:, 3:]):\n",
        "fit kısmı: Eğitim setindeki verilerden ortalama ve standart sapma değerleri hesaplanır.\n",
        "transform kısmı: Hesaplanan ortalama ve standart sapma kullanılarak eğitim setindeki her bir değer, standartlaştırılır.\n",
        "Eğitim setine bu işlem uygulanır, çünkü model bu verilerle eğitilecektir ve test setinin istatistiklerinden bilgi alınmamalıdır.\n",
        "\n",
        "2. Test Setine Sadece transform Uygulanması\n",
        "sc.transform(X_test[:, 3:]):\n",
        "Test setine yalnızca eğitim setinden öğrenilen ortalama ve standart sapma değerleriyle dönüştürme işlemi yapılır.\n",
        "Test setine fit uygulanmaz, çünkü test setindeki istatistikler modele asla verilmemelidir.\n",
        "3. Neden? (Data Leakage - Veri Sızması)\n",
        "Eğer test setine de fit uygulanırsa:\n",
        "\n",
        "Test Setinin Özellikleri Model Tarafından Bilinir:\n",
        "\n",
        "Test setindeki verilerden öğrenilen ortalama ve standart sapma, dolaylı olarak modele aktarılır.\n",
        "Bu, test setinin \"görülmemiş veri\" olma özelliğini bozar ve modelin gerçek performansı doğru ölçülemez.\n",
        "Gerçek Dünya Senaryosu Simüle Edilemez:\n",
        "\n",
        "Gerçek hayatta model, sadece eğitim verileriyle eğitilir. Test seti, tamamen yeni, modelin daha önce görmediği verilerden oluşur.\n",
        "Test setinin istatistiklerini kullanmak, modelin gerçek hayatta karşılaşacağı durumları simüle etmeyi engeller."
      ],
      "metadata": {
        "id": "9Y5SaUlQrb6K"
      }
    }
  ]
}